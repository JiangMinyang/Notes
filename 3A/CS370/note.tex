\documentclass[10pt,usletter]{article}
\usepackage[letterpaper, hmargin=0.75in, vmargin=0.75in]{geometry}
\usepackage{graphicx}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{pgf}
\usepackage{courier}
\usepackage{amsfonts,amssymb,amsmath,amsthm,lastpage,fancyhdr,wrapfig,multirow}
\usepackage{palatino}
\usepackage{amsmath}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\textwidth 7.5in
\oddsidemargin -.5in
\topmargin -0.70in
\textheight 9.8in                      

\pagestyle{fancy}

%**************Fill in your ID and initials here*****************
\newcommand{\mc}[1]{\ensuremath{\mathcal{{#1}}}}
\newcommand{\mb}[1]{\ensuremath{\mathbb{{#1}}}}
\newcommand{\mf}[1]{\ensuremath{\mathfrak{{#1}}}}
\newcommand{\N}[1]{\ensuremath{\{1,\ldots,{#1}\}}}

\newcommand{\Worth}[1]{\{{#1} marks\}}
\newcommand{\Sln}{\smallskip \textbf{Solution.} }
\newcommand{\Extra}[1]{\{Extra credit: {#1} marks\}}


\setlength{\parskip}{0.15in}
\setlength{\parindent}{0in}


\newcommand{\NP}{\newpage \vspace*{-0.4in}}
\newcommand{\FP}{\vspace*{-0.6in}}
\newcommand{\tab}[1][1cm]{\hspace*{#1}}

\lstset{ %
language=Java,
basicstyle=\ttfamily\scriptsize,commentstyle=\scriptsize\itshape,showstringspaces=false,breaklines=true}


\title{\huge CS370 Notes}
\author{Minyang Jiang}
\date{\today}

\begin{document}

\maketitle

\NP
\section{Floating Point Number Systems}
\subsection{Introduction}
$$F(\beta, t, L, u)$$
continas:
\begin{center}
0 or $\pm 0.\beta_1\beta_2...\beta_t * \beta^d$ \\
where $\beta_1 \neq 0$ \\ 
$0 \leq \beta_i \le \beta$ \\
$L \leq d \leq u$
\end{center}
Two common systems used today - Base 2
\begin{enumerate}
\item Single precision: $F(2, 24, -126, 127)$ 
\item Double precision: $F(2, 53, -1022, 1023)$ 
\end{enumerate}
Important concepts\\
If $x$ is any real number then set $fl(x)=$ floating point representation of x \\
if we write: $$x=\pm 0.x_1x_2x_3...x_tx_{t+1}...*\beta^d$$
$$fl(x)=\pm 0.x_1x_2x_3...x_t*\beta^d$$
relative error $$\delta_x = \frac{fl(x)-x}{x}$$
$$\|\delta_x\| \leq ?$$
\begin{align*}
\frac{\|fl(x)-x\|}{\|x\|}&= \frac{0.00\hdots0x_{t+1}\hdots*\beta^d}{0.x_1x_2\hdots x_{t+1}\hdots*\beta^d} \\
&=\frac{0.x_{t+1}x_{t+2}\hdots*\beta^{-t}}{x_1.x_2\hdots * \beta_{-1}}\\
\delta &= \frac{fl(x)-x}{x} \tab \text{then } \|\delta\| \leq \epsilon =
\begin{cases}
\beta^{1-t} \\
\frac{\beta^{1-t}}{2} \
\end{cases}\\
fl(x)&=x(1+\delta) \tab |\delta| \le \epsilon \\
\end{align*}
What about floating point arithmetic? \\
\tab x, y  real numbers, $x+y$ real\\
\tab $x\oplus y = $addition inside floating pt system $=fl(fl(x) + fl(y))$

\subsection{Analysis some errors in computation}
Example. Addition
\begin{align*}
\left\|\frac{(x+y)-(x\oplus y)}{x + y}\right\|&=\frac{\|(x+y)-fl(fl(x)+fl(y))\|}{x+y}=\frac{\|x+y-x(1+\delta)+y(1+\delta)\|}{x+y}\\
&=\frac{\|x+y-(x+y+\delta_1 x+\delta_2 y + x\delta_3 + y\delta_3 + \delta_1\delta_3 x+ \delta_2 \delta_3 y)\|}{x+y}\\
&\leq \frac{\|\delta_1 x\|+\|\delta_2 y\| + \|\delta_3 x\| + \|\delta_3 y\| + \delta_1\delta_3 x + \|\delta2\delta_3 y\|}{\|x+y\|}\\
&\le \frac{(\|x\|+\|y\|)(2\epsilon + \epsilon^2)}{\|x+y\|} \\
\|\delta_1\| \le \epsilon,\tab &\|\delta_2\| \le \epsilon,\tab \|\delta_3\| \le \epsilon
\end{align*}
$\Rightarrow$ if x and y have same sign then relative error of addition $$\left\|\frac{x \oplus y - (x+y)}{x+y}\right\| \le 2\epsilon + \epsilon^2$$
However if x and y have opposite sign, then you potentially have a problem particularly when $x+y \approx 0$, Situation is called \textbf{Catastrophic cancellation}
\begin{align*}
x&= 0.x_1x_2\hdots x_{t-1} x_t x_{t+1}\hdots * \beta^d\\
y&=-0.x_1x_2\hdots x_{t-1} x_t x_{t+1}\hdots * \beta^d\\
x+y&= 0.00\hdots0??\hdots * \beta^d\\
\end{align*}

\subsection{How about some algorithms?}
\subsubsection{Example}
Given $\alpha$, compute: $$I_n=\int_0^1\frac{x^n}{x+\alpha}dx \tab n=0,1,\hdots,100\hdots$$
\underline{Step 1} $$I_0=\int_0^1 \frac{1}{x+\alpha}dx=Ln(x+\alpha)=Ln(1+\alpha)-Ln(\alpha)=Ln\left(\frac{1+\alpha}{\alpha}\right)$$
e.g.
\begin{align*}
\alpha = 0.5 \text{ then } I_0=1.098612288668\hdots\\
\alpha = 2.0 \text{ then } I_0=0.405465108108\hdots\\
\end{align*}
\underline{Step 2} \tab Notice: $$I_{n+1}=\int_0^1\frac{x^{n+1}}{x+\alpha}dx=\int_0^1\frac{x^n(x+\alpha-\alpha}{x+\alpha}dx=\int_0^1x^ndx-\alpha\int_0^1\frac{x^n}{x+\alpha}dx$$
$$I_{n+1}=\frac{1}{n+1}-\alpha I_n$$
\begin{align*}
I_0&\\
I_1 &= 1-\alpha I_0\\
I_2 &= \frac{1}{2} - \alpha I_1\\
\vdots\\
I_{100} &= \frac{1}{100} - \alpha I_00
\end{align*}
If $\alpha = 0.5$ then $I_{100} = 0.00664$\\
if $\alpha = 2.0$ then $I_{100} = 2.1 * 10^{22}$\\
$$\|I_n\| \leq \frac{1}{1+\alpha}$$
Let's analyze what is happening \\
\underline{Math}: $$I_0^{ex}, I_{n+1}^{ex}=\frac{1}{n+1}-\alpha I_n^{ex}$$ 
\underline{CS}:	$$I_0^{app}, I_{n+1}^{app}=\frac{1}{n+1}-\alpha I_n^{aop}$$
At every step, therer is some error:
\begin{align*}
e_0&=I_0^{ex}-I_0^{app} \\
e_n&=I_0^{ex}-I_n^{app}
\end{align*}
\underline{Notice:} 
\begin{align*}
e_{n+1}&=I_{n+1}^{ex}-I_{n+1}^{app} \\
&=\left(\frac{1}{n+1}-\alpha I_n^{ex}\right)-\left(\frac{1}{n+1}-\alpha I_n^{app}\right) \\
&=-\alpha I_n^{ex}+\alpha I_n^{app} \\
&=-\alpha \left(I_n^{ex}-I_n^{app}\right) \\
&=-\alpha e_n \\
&=(-\alpha)^{n+1}e_0
\end{align*}
If $\|\alpha\|\le 1$ then $\|e_n\|\rightarrow 0$ as $n\rightarrow \inf$\\
If $\|\alpha\|\ge 1$ then $\|e_n\|\rightarrow \inf$ as $n\rightarrow \inf$\\
What to do when $\|\alpha\| \ge 1$:
\begin{align*}
I_n&=\frac{1}{\alpha (n+1)} - \frac{1}{\alpha} I_{n+1}\\
e_n&=-\frac{1}{\alpha}e_{n+1}
\end{align*}
If $\|\alpha\| \ge 1$ then work backwards, e.g. $I_{100}$, Do $I_{200}, I_{199}\hdots$
\NP
\section{Interpolation}
Given n points $(x_1, y_1),\hdots, (x_N, y_N)$ $x_i$ distinct $x_1<x_2<\hdots<x_N$ \\
$y=p(x)$, p should be 'nice'\\
'nice':
\begin{enumerate}
\item[â€¢] polynomial; piecewise polynomial;
\end{enumerate}
\subsection{Polynomial Interpolation}
Given n points $(x_i, y_i)$  $i=1,2,\hdots,n$\\
Find a \underline{polynomial} having degree $<n$ satisfying $p(x_i)=y_i$\\
\underline{Example}\\
$(-1,3),(1,1), (2,2)$\\
\begin{align*}
p(x)&=c_0+c_1x+c_2x^2\\
p(-1)&=c_0-c_1+c_2=3\\
p(1)&=c_0+c_1+c_2=1\\
p(2)&=c_0+2c_1+4c_2=2
\end{align*}
$$
\begin{bmatrix}
1 & -1 & 1 & 3\\
1 & 1 & 1 & 1\\
1 & 2 & 4 & 2
\end{bmatrix}
$$
$$p(x)=\frac{4}{3} - x + \frac{2}{3}x^2$$
Given n points $(x_1, y_1),\hdots, (x_N, y_N)$ $x_i$ distinct $x_1<x_2<\hdots<x_N$ 
\begin{enumerate}
\item[1)] Does there exist a polynomial $p(x)$ of degree < n which interpolate the n points?
\item[2)] If it exists then is it unique?
\end{enumerate}
$$(x_1,y_1), (x_2,y_2), \dots, (x_n, y_n)$$
$$p(x)=c_1+c_2x+\hdots +c_nx^{n-1}$$
n unknowns\\
n equations
\begin{align*}
c_1+c_2x_1+\hdots +c_nx_1^{n-1}&=y_1\\
c_1+c_2x_2+\hdots +c_nx_2^{n-1}&=y_2\\
\vdots\\
c_1+c_2x_n+\hdots +c_nx_n^{n-1}&=y_n
\end{align*}
Vamdeimonde matrix
$$V \cdot\vec{c}=\vec{y}$$
$$det(V)=\Pi_{i>j}(x_i-x_j)\neq 0 \tab \text{since all $x_i$ distinct}$$
\subsection{\underline{Lagrange Form of Interpolating Polynomial}}
\begin{align*}
p(x)&=c_1+c_2x+c_3x^2+\hdots+c_nx^{n-1}\\
&=y_1L_1(x)+y_2L_2(x)+\hdots + y_nL_n(x)
\end{align*}
where each $L_i(x)$ is a polyominal of degree $<n$ which satisfies $L_i(x_i)=1, L_i(x_j)=0$ if $i \neq j$\\
$L_i(x)\equiv$ Lagrange polynominal
$$L_i(x)=\frac{(x-x_1)\hdots (x-x_{i-1})(x-x_{i+1})\hdots (x-x_n)}{(x_i-x_1)\hdots (x_i-x_{i-1})(x_i-x_{i+1})\hdots (x_i-x_n)}$$

\subsection{Hermite Interpolation}
Points: $(x_L,y_L),(x_R,y_R)$\\
Derivative values: $S_L, S_R$\\
$S(x)$ degree $<4$, $S(X_L)=Y_L,S(X_R)=Y_R, S'(X_L)=S_L, S'(X_R)=S_R$, Find $S(X)$
\begin{align*}
S(x) =& c_1+c_2(x-x_L)+c_3(x-x_L)^2+c_4(x-x_L)^3\\
&\begin{bmatrix}
1 & 0 & 0 & 0 & y_L\\
0 & 1 & 0 & 0 & s_L\\
1 & \Delta x & \Delta x^2 & \Delta x^3 & y_R\\
0 & 1 & 2 \Delta x & 3 \Delta x^2 &s_R
\end{bmatrix}\\
=&
\begin{bmatrix}
1 & 0 & 0 & 0 & 2\\
0 & 1 & 0 & 0 & -1\\
1 & 2 & 4 & 8 & 4\\
0 & 1 & 4 & 12 & -1
\end{bmatrix}\\
y_L'=&\frac{y_R-y_L}{x_R-x_L}=slope\\
c_1=&y_L\\
c_2=&s_L\\
c_3=&\frac{3y_L'-2s_L-s_R}{\Delta x}\\
c_4=&\frac{s_L+s_R-2y_L'}{\delta	x^2}
\end{align*}

\underline{Point} Polynomial interpolation is good at the interpolating points but might not be very good elsewhere

We will need to try other methods to fit data, cubic splines

\subsection{Cubic Splines}
Given N points: $(x_i, y_i)$\\
A \underline{cubic spline} is a function $S(x)$ which satisfies the following conditions
\begin{enumerate}
\item in each interval $[xi, x_{i+1}]$, $S(x)=S_i(x)$ is a polynomial of degree at most 3.
\item $S(x)$ interpolates the points $(x_1,y_1),\hdots,(x_N,y_N)$
\item $S'(x)$ exists and in continuous everywhere in $[x_1, x_N]$
\item $S''(x)$ exists and in continuous everywhere in $[x_1,x_N]$
\item 2 Boundary Conditions
\end{enumerate}
As it stands as cubic spline problem has $A$ unknowns and $B$ equations, We want $A=B$\\
How many unknowns?\\
4 unknowns per interval, $N-1$ intervals $\Rightarrow 4(N-1)=4N-4$ unknowns\\
How many equations?\\
Condition (2): 2 per interval $\Rightarrow 2(N-1)=2N-2$\\
Condition (3): 1 per interier pt $N-2$\\
Condition (4): 1 per interier pt $N-2$\\
$2N-2+N-2+N-2=4N-6$\\
There fore need 2 more conditions

\underline{Typical Boundary Conditions}
\begin{enumerate}
\item Natural spline $S''(x_1)=0, S''(x_N)=0$
\item Clamped spline $S'(x_1)=s_1, S'(x_N)=s_n$, $s_1,s_n$ given
\item periodic spline $S'(x_1)=S'(x_N), S''(x_1)=S''(x_N)$
\item Not-a-knot (Matlab default) $S'''$ continuous at $x_2, x_{N-1}$
\end{enumerate}
How to compute a cubic spline?
\begin{enumerate}
\item Set a system of $4N-4$ equations in the $4N-4$ unknowns
\end{enumerate}
$$S_i(x)=a_i+b_i(x-x_i)+c_i(x-x_i)^2+d_i(x-x_i)^3$$
Solving Cost: $O(N^3)$
We want a method which compute a cubic spline using $O(N)$ operations\\
Set up a linear system for the unknown derivative values $s_1,s_2,\hdots,s_n$ which will be fast to solve and which will give us $S_1(x),\hdots,S_{N-1}(x)$

\underline{Cubic Splines (continued)}\\
How to set up a linear system to compute S(x) efficiently!\\
We do this for \underline{natural} spline,\\
Find each ($i=1,2,3,\hdots,N-2$)
$$S_i(x)=a_i+b_i(x-x_i)+c_i(x-x_i)^2+d_i(x-x_i)^3$$

Given n points $(x_1, y_1),\hdots, (x_N, y_N)$ $x_i$ (knowns)
Let $s_1,s_2,s_3,\hdots,s_N$ be the corresponding derivatives at these points. These will be the unknowns.\\
\underline{Equation 1}
\begin{align*}
S''(x_1)&=0 \\
S_1''(x_1)&=0 \\
2c_1&=0\\
\frac{3y_1'-2s_1-s_2}{\Delta x_1}&=0\\
s_1+\frac{1}{2}s_2&=\frac{3y_1'}{2}
\end{align*}
\underline{Equation N}
\begin{align*}
S''(x_n)&=0\\
S''_{n-1}(x_n)&=0\\
2c_{n-1}+6d_{n-1}(x_n-x_{n-1})&=0\\
\frac{3y_L'-2s_{n-1}-s_{n}}{\Delta x}+\frac{3(s_{n-1}+s_n-2y_L')}{\Delta x}&=0\\
S_{n-1}+2S_n&=3y_{n-1}'
\end{align*}
\underline{Equation 2,3,...N-1}\\
At each interier point $x_i$, we need $S''(x)$ to be continuous
\begin{align*}
S_{i-1}''(x_i)&=S_i''(x_i)\\
2c_{i-1}+6d_{i-1}(x_i-x_{i-1})&=2c_i\\
c_{i-1}+3d_i\Delta x_{i-1}&=c_i\\
\frac{3y_L'-2s_{i-1}-s_i}{\Delta x_{i-1}}+\frac{3(s_{i-1}+s_i-2y_L')}{\Delta x_{i-1}}&=\frac{3y_i'-2s_i-2s_{i+1}}{\Delta x_i}\\
\Delta x_i s_{i-1}+(2x_i+2\Delta x_{i-1}) s_i+ \Delta x_{i-1}s_{i+1}&=3y_{i-1}'\Delta x_i + 3y_i' \Delta x_{i-1}
\end{align*}
\subsection{Interpolation Parameterized Curves}
let x and y each be separate functions of a new parameter,t.\\
Then a point's position is given by the vector $\vec{p(t)}=(x(t),y(t))$\\
The parameter t increases monotonically along the curve, but x and y may increase and decrease as needed to describe any shape.\\
\underline{parametric curves - non-uniqueness}\\
A given curve can be parameterized indifferent ways, while yielding the exact same cure.\\
parameterizations can also traverse the curve in the same direction, but at \textbf{different speeds/rates}.\\
$$\frac{d\vec{p(t_0)}}{dt}=(x'(t_0),y'(t_0))$$

\subsubsection{Arc-Length parameterization}
A common parameterization is to use the distance along the curve as the parameter,t.\\
This gives a ""unit speed" traversal of the curve

\section{Ordinary Differential Equation}

$$y'(t)=f(t,y(t))$$

\subsection{Time Stepping}
Given initial conditions, we repeatedly step sequentialy forward to the next time instant, using the derivative info, y', and a timestep,h
Set $n=0,t=t_0,y=t_0,h=h_0$
\begin{enumerate}
\item Compute $h_n$ and $y_{n+1}$\\
\item increment time, $t_{n+1}=t_n+h_n$\\
\item advance $n=n+1$\\
\item repeat
\end{enumerate}

\begin{enumerate}
\item[â€¢] Single-step: use dynamics function f and current info, $(t_n,y_n)$\\
\item[â€¢] use dynamics function f and info from both current and previous timesetops
\end{enumerate}

Forward Euler
$$y_{n+1}=y_n+hf(t_n,y_n)$$

\underline{Deriving Forward Euler}\\
Approximate y' with a finite difference\\
ODE: $y'(t)=f(t,y(t))$\\
Finite dif: $y'(t)=\frac{y_{n+1}-y_n}{h}$\\

\underline{Approach \#2}\\
use a truncated Taylor series to estimate $y(t_{n+1})$
$$y(t_{n+1})=y(t_n+h)=y(t_n)+hy'(t_n)+\frac{h^2}{2}y''(t_n)+O(h^3)$$


\underline{Improved Euler Example}\\
Generic form $$y_{n+1}^*=y_n+hf(t_n,y_n)$$
$$=y_{n+1}+\frac{h}{2}[f(t_n,y_n)+f(t_{n+1},y_{n+1}^*]$$

\underline{Tropezoidal example}
Generic trapezoidal $$y_{n+1}=y_n+\frac{h}{2}[f(t_n,y_n)+f(t_{n+1},y_{n+1})]$$
For this problem,with $n=2$ we have:
$$x_{n+1}=x_n+\frac{2}{2}[-y_n-y_{n+1}]$$
$$y_{n+1}=y_n+\frac{2}{2}[x_n+x_{n+1}]$$
This is a linear system of equations to solve \underline{per step}, since trapezoidal is implicit
\begin{align*}
x_{n+1}+y_{n+1}&=x_n-y_n\\
-x_{n+1}+y_{n+1}&=x_n+y_n
\end{align*}
For othe problems, the system may be \underline{nonlinear} so more expensive to solve



\underline{Deriving B.E. via interpolation}
Ft Lagrange polynomial $p(t)$ to $(t_n,y_n)$ and $(t_{n+1},y_{n+1})$
\begin{align*}
p(t)=y_n(\frac{t - t_{n+1}}{t_n-t_{n+1}})+y_{n+1}(\frac{t-t_n}{t_{n+1}-t_n})\\
p'(t)=\frac{y_{n+1}-y_n}{h}=f(t_{n+1},y_{n+1})\rightarrow y_{n+1}=y_n+hf(t_{n+1},y_{n+1})
\end{align*}

convert a 4th order ODE to a 1st order system
convert
$$y''''(t)-3y'(t)y'''(t)+\sin(ty''(t))-7t[y(t)]^2=e^t$$
to a 1st order system\\
\begin{align*}
y_1(t)=y(t)\\
y_2(t)=y'(t)\\
y_3(t)=y''(t)\\
y_4(t)=y'''(t)\\
\end{align*}


\begin{align*}
y''''(t)=3y_x(t)y_4(t)-sin(ty_3(t))+7t[y_1(t)]^2+e^t\\
y_1'(t)=y_2(t)\\
y_2'(t)=y_3(t)\\
y_3'(t)=y_4(t)\\
\end{align*}
This gives a 1st order system of ODEs that can be treated with any earlier method


\underline{Stability of FE}
F.E is $y_{n+1}=y_n+hf(t_n,y_n)$\\
Test equation is $y'(t)=-\lambda y(t)$ for $\lambda > 0$\\
Applying F.E. to test equation given:
$$y_{n+1}=y_n+h(-\lambda y_n)=y_n(1-h\lambda)$$\\
Closed form is $$y_n=y_0(1-h\lambda)^n$$\\
True solution is $y(t)=y_0e^{-\lambda t}$, which decays to zero\\
Forward Euler decays to 0 when $\|1-h\lambda\|<1\Rightarrow 0 <h < \frac{2}{\lambda}$\\
If we perturb the initial conditions by some error $\epsilon_0$ how does the error propogate?
\begin{align*}
y_0^{(p)}=y_0+\epsilon_0\Rightarrow y_n^{(p)}=(1-h\lambda)^n(y_0+\epsilon_0)\\
\text{Error is } \epsilon_0=(1-h\lambda)^n\epsilon_0
\end{align*}


\underline{Stabilllity of Backwards Euler}
B.E. is $y_{n+1}=y_n+hf(t_{n+1},y(n+1))$
applied to the test equation $$y_{n+1}=y_n+h(-\lambda y_{n+1})$$
rearranging for $y_{n+1}$ gives $$y_{n+1}=\frac{y_n}{1+h\lambda}$$
perturbing initial conditions by $\epsilon_0$ as for F.E shows the some behavior:
$$\epsilon_n=\frac{\epsilon_0}{(1+h\lambda)^n}$$
The denominator should be $>1$ for this to decrease Since $h>0$ and $\lambda>0$, error decreases for any timestep\\
We call this behaviour unconditional stable


\subsection{Truncation Error}
local truncation error is $$LTE=y(t_{n+1})-y_{n+1}$$
\begin{enumerate}
\item replace approximations on RHS with exact versions. $y_n\rightarrow y(t_n)$ an d $f(t_{n+1},y_{n+1})\rightarrow y'(t_{n+1})$
\item taylor expand all RHS
\end{enumerate}
\underline{Truncation rror of Trapezoidal}
\begin{enumerate}
\item Replace RHS data with exact data $y_{n+1}=y_n+\frac{h}{2}(f(t_n, y_n)+f(t_{n+1},y_{n+1}))\rightarrow y_{n+1}=y(t_n)+\frac{h}{2}(y'(t_n)+y'(t_{n+1}))$
\item Tayloy expand RHS terms about $t_n$:
$$y'(t_{n+1})=y'(t_n)+hy''(t_n)+\frac{h^2}{2}y'''(t_n)+O(h^3)$$ 
Plugging in 
$$y_{n+1}=y(t_n)+\frac{h}{2}(y'(t_n)+y'(t_n)+hy''(t_n)+\frac{h^2}{2}y'''(t_n)+O(h^3)))$$
$$=y(t_n)+hy'(t_n)+\frac{h^2}{2}y''(t_n) + \frac{h^3}{4}y'''(t_n)+O(h^4)$$
\item Exact solution:
$$y(t_{n+1})=y(t_n)+hy'(t_n)+\frac{h^2}{2}y''(t_n)+\frac{h^3}{6}y'''(t_n)+O(h^4)$$
\item Difference is:
$$y(t_{n+1})-y_{n+1}=O(h^3)$$
\end{enumerate}

\underline{Truncation error for BDF2}
BDF2: $$y_{n+1}=\frac{4}{3}-\frac{1}{3}y_{n-1}+\frac{2}{3}f(t_{n+1},y_{n+1})$$
\begin{enumerate}
\item replace RHS data with exact $$y_{n+1}=\frac{4}{3}y(t_n)-\frac{1}{3}y'(t_{n-1})+\frac{2}{3}y'(t_{n+1})$$
\item Taylor expand about $t_n$:
$$y'(t_{n+1})=y'(t_n)+hy''(t_n)+\frac{h^2}{2}y'''(t_n)+O(h^3)$$
$$y'(t_{n-1})=y(t_n)-hy'(t_n)+\frac{h^2}{2}y''(t_n)-\frac{h^3}{6}y'''(t_n)+O(h^4)$$
\item exact sln:
$$y_{n+1}=y(t_n)+hy'(t_n)+\frac{h^2}{2}y''(t_n)+\frac{7}{18}h^3y'''(t_n)+O(h^4)$$
\item differences is:
$$y(t_{n+1})-y_{n+1}=\frac{2}{9}y'''(t_n)+O(h^4)=O(h^3)$$
\end{enumerate}



\subsection*{Adaptive Time Stepping}
$y'(t)=f(t,y(t)),y_0=y(t_0)$\\
Answer, $(t_0,y_0),(t_1,y_1),(t_2,y_2),(t_3,y_3),\hdots,(t_n,y_n), y_n \approx y(t_n)$\\
How to take big time steps? (while still getting a good answer)\\
Answer: Use 2 methods simultameously\\
Let us look at 2 methods:\\
\underline{Method 1} local order p (p-1)th order method\\
\underline{Method 2} clocal order p+1, pth order method\\

\underline{Method 1}\\
$$y_{n+1}^*=y(t_{n+1})+O(h^p)=y(t_{n+1})+Ah^p+\text{higher order terms}$$
\underline{Method 2}\\
$$y_{n+1}=y(t_{n+1})+O(h^{p+1})=y(t_{n+1})+\text{ higher order terms}$$

Local error for 1st method?\\
Local error $\approx Ah^p$\\
Step 1: check if $|$local error$| <$ TOL than try doubling time step, else try half step size\\
Step 2: Supposee $|y_{n+1}^*-y_{n+1}\approx|$ local error $<$ TOL, how do we choose our next time step\\
\begin{align*}
y_{n+1}^*=y(t_{n+2})+O(\tilde h^p)\\
=y(t_{n+2})+A\tilde h^p+hots\\
y_{n+2}=y(t_{n+2})+O(\tilde h^{p+1})\\
error = y_{n+2}^*-y_{n+2}\approx A h^p=\text{local error} * \frac{\tilde h^p}{h^p}
\end{align*} 
\begin{align*}
|\text{local error}|\frac{\tilde{h}^p}{h}\approx |y_{n+2}^*-y_{n+2}<TOL|\\
\frac{\tilde{h}^p}{h^p}=\frac{0.8\text{TOL}}{|y_{n+1}^*-y_{n+1}|}\\
\tilde{h}=h(\frac{0.8\text{TOL}}{|y_{n+1}^*-y_{n+1}|})^{\frac{1}{p}}
\end{align*}

\section{Discrete Fouris Analysis}
input: $f_0,f_1,\hdots, f_{N-1}$, typically $N=2^n$, typically represents N equally spaced samples of a function f(t)
output: $F_0,F_1,\hdots,F_{N-1}$ represent frequency information in the input data














\end{document}
